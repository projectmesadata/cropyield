{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%html\n",
    "<script>\n",
    "    // AUTORUN ALL CELLS ON NOTEBOOK-LOAD!\n",
    "    require(\n",
    "        ['base/js/namespace', 'jquery'], \n",
    "        function(jupyter, $) {\n",
    "            $(jupyter.events).on(\"kernel_ready.Kernel\", function () {\n",
    "                console.log(\"Auto-running all cells-below...\");\n",
    "                jupyter.actions.call('jupyter-notebook:run-all-cells-below');\n",
    "                jupyter.notebook.scroll_to_top();\n",
    "                jupyter.actions.call('jupyter-notebook:save-notebook');                \n",
    "                \n",
    "            });\n",
    "        });\n",
    "        \n",
    "        $( document ).ready(function(){\n",
    "        code_shown=false;\n",
    "        $('div.input').hide()});\n",
    "    \n",
    "    \n",
    "</script>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: Above this cell is a hidden cell that hides and runs all code in the file. This is intended for those who do not want to see or interact with the code. It can be seen by converting the cell to markdown(see toolbar above) and then back to code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "This script provides the water satisification requirement index (WSRI) at a given location over time. It uses the downloaded [Famine Land Data Assimilation System](https://ldas.gsfc.nasa.gov/FLDAS/) (FLDAS)* data which can be acquired through the Crop Yield Data Download script. \n",
    "\n",
    "This notebook will take you step by step from the data to output.\n",
    "\n",
    "Contributions to provide improvements are welcome.\n",
    "\n",
    "\\**McNally, A., Arsenault, K., Kumar, S., Shukla, S., Peterson, P., Wang, S., Funk, C., Peters-Lidard, C.D., & Verdin, J. P. (2017). A land data assimilation system for sub-Saharan Africa food and water security applications. Scientific Data, 4, 170012*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Tips\n",
    "\n",
    "- **Every cell ran when the notebook opened**\n",
    "\n",
    "\n",
    "- **Each input is \"live\"; entering an input then running the cell will delete your input**\n",
    "\n",
    "\n",
    "- **After making an input each cell below that input needs to be rerun to use that new input**\n",
    "\n",
    "\n",
    "- **If you get an error rerun the cells above the cell that errored and it will rectify**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0: Python Dependencies \n",
    "\n",
    "This cell imports the python dependencies we use to download the data. It has already run, but if click the run cell button, the buttons for this cell will disappear. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "\"hide-input\""
    ]
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "from toggle_code import toggle_code as hide_code\n",
    "from toggle_code import run_code as run_code\n",
    "\n",
    "import glob \n",
    "from netCDF4 import Dataset\n",
    "import pandas as pd\n",
    "import numpy as np2\n",
    "import math\n",
    "import pcse\n",
    "import datetime\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "from bokeh.io import push_notebook, show, output_notebook\n",
    "from bokeh.plotting import figure\n",
    "from bokeh.tile_providers import get_provider, Vendors\n",
    "from bokeh.palettes import Spectral4\n",
    "from bokeh.models import Legend, BoxAnnotation, Toggle\n",
    "from bokeh.layouts import layout, gridplot, column\n",
    "tile_provider = get_provider('STAMEN_TERRAIN')\n",
    "#create pyproj transformer to convert form lat/long to web mercator\n",
    "from pyproj import Transformer\n",
    "transformer = Transformer.from_crs('epsg:4326','epsg:3857')\n",
    "#from IPython.display import HTML\n",
    "output_notebook()\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"Cannot find a last shown plot to update.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Initializing the data\n",
    "\n",
    "Next, we store the max and min dates from our list of months, so we can create a table (dataframe) with an index for the climate data from each month. We also add the column variables that we want to extract to the dataframe. \n",
    "\n",
    "Now we have an empty dataframe to fill with the downloaded data for the variables we need to calculate different crop growths\n",
    "\n",
    "*If you want to look at all the possible variables to extract from the FLDAS dataset you can open the code and delete the # in front of the print(data.variables.keys()) line below.* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "\"hide-input\""
    ]
   },
   "outputs": [],
   "source": [
    "hide_code()\n",
    "run_code()\n",
    "#Retrieve the dates form the downlaoded files to serves as an index for the dataframe\n",
    "all_months = []\n",
    "#print(\"The following dates were downloaded:\")\n",
    "#Retrieves dates to create index list form downloaded files\n",
    "for file in glob.glob(r'data/*.nc4'):\n",
    "    #print(file)\n",
    "    data = Dataset(file, 'r')\n",
    "    #time = data.variables['time'].units\n",
    "    #print(time)\n",
    "    date = file[26:30] + '-' + file[30:32]\n",
    "    #month = time[11:21]\n",
    "    all_months.append(date)\n",
    "    #print(time)\n",
    "    #print (date)\n",
    "\n",
    "#Retrieve elevevation data and stores in a dictionary of\n",
    "# Key = Long, Lat pair\n",
    "# Value = Elevation\n",
    "elev_dict = {}\n",
    "for file in glob.glob(r'data/*.csv'):\n",
    "    elev = pd.read_csv(file)\n",
    "    for idx, row in elev.iterrows():\n",
    "        elev_dict[(row[\"Latitude\"],row[\"Longitude\"])] =row[\"Elevation\"]\n",
    "\n",
    "\n",
    "# sort months of python list\n",
    "all_months.sort( )\n",
    "\n",
    "month_start = min(all_months)\n",
    "month_end = max(all_months)\n",
    "#print(\"Start:\", month_start)\n",
    "#print(\"Month End:\", month_end)\n",
    "date_range = pd.date_range(start = month_start, end = month_end, freq = 'MS' )\n",
    "\n",
    "#print(data.variables.keys())\n",
    "\n",
    "#creates an empty data frame with the dates\n",
    "df = pd.DataFrame(0.0, columns = ['air_temp' , 'humidity' , 'net_short_radiation', 'net_long_radiation', 'wind_speed', 'evapotranspiration'], index = date_range)\n",
    "df.index.name = 'Date'\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get the specific location to assess \n",
    "\n",
    "Here is where you can input your desired location to calculate the Water Requirements Satisficiation Index and Crop Yield over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "\"hide-input\""
    ]
   },
   "outputs": [],
   "source": [
    "hide_code()\n",
    "run_code()\n",
    "file_loc = r\"data/FLDAS_NOAH01_C_GL_M.A\" + all_months[0][0:4]+all_months[0][5:7] + \".001.nc.SUB.nc4\"\n",
    "data_loc =Dataset(file_loc, 'r')\n",
    "lat_array = data_loc.variables['Y'][:]#.compressed() # unmasks numpy_array lat stored in the FLDAS files \n",
    "long_array = data_loc.variables['X'][:]#.compressed() # unmasks numpy array long stored in FLDAS files\n",
    "min_lat = lat_array[0]\n",
    "max_lat = lat_array[-1]\n",
    "min_long = long_array[0]\n",
    "max_long = long_array[-1]\n",
    "long_points = {'globe':[], 'web':[]}\n",
    "lat_points = {'globe':[], 'web':[]}\n",
    "for i in range(len(lat_array)):\n",
    "    for j in range(len(long_array)):\n",
    "        if round(lat_array[i],2) not in lat_points['globe']:\n",
    "            lat_points['globe'].append(round(lat_array[i],2))\n",
    "        if round(long_array[j],2) not in long_points['globe']:\n",
    "            long_points['globe'].append(round(long_array[j],2))\n",
    "        pt = transformer.transform(lat_array[i], long_array[j])\n",
    "        if pt[0] not in long_points['web']: \n",
    "            long_points['web'].append(pt[0])\n",
    "        if pt[1] not in lat_points['web']:\n",
    "            lat_points['web'].append(pt[1])\n",
    "            \n",
    "pts = [(min_lat, min_long), (max_lat, max_long)]\n",
    "bbox = []\n",
    "for pt in transformer.itransform(pts): \n",
    "    bbox.append(pt)       \n",
    "p = figure(x_range=(bbox[0][0], bbox[1][0]),y_range=(bbox[0][1], bbox[1][1]),x_axis_type=\"mercator\", y_axis_type=\"mercator\")\n",
    "#add the map form the Bokeh map vendor in this case Stamen_Terrain --- see documentation\n",
    "p.add_tile(tile_provider)\n",
    "y = [lat_points[\"web\"][50]]\n",
    "x = [long_points[\"web\"][80]]\n",
    "loc = p.square(x,y, color= \"red\", size = 10, alpha = 0.5)\n",
    "\n",
    "\n",
    "def update(latitude, longitude):\n",
    "    idx_long = long_points[\"globe\"].index(longitude)\n",
    "    idx_lat = lat_points[\"globe\"].index(latitude)\n",
    "    loc.data_source.data['x'] = [long_points[\"web\"][idx_long]]\n",
    "    loc.data_source.data['y'] = [lat_points[\"web\"][idx_lat]]\n",
    "    push_notebook()\n",
    "    return longitude, latitude\n",
    "    \n",
    "loc_input = interact(update,latitude=(lat_points[\"globe\"][0], lat_points[\"globe\"][-1]), \n",
    "                     longitude=(long_points[\"globe\"][0],long_points[\"globe\"][-1]))\n",
    "\n",
    "show(p, notebook_handle=True)\n",
    "print (\"  \") #Hides the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Knowing the Data\n",
    "\n",
    "The next several cells show the data from the selected location and transform it so we can assess crop yields. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "tags": [
     "\"hide-input\""
    ]
   },
   "outputs": [],
   "source": [
    "hide_code()\n",
    "run_code()\n",
    "# Get user input form sliders\n",
    "lat_user = loc_input.__dict__[\"widget\"].children[0].__dict__[\"_trait_values\"][\"value\"]\n",
    "lon_user = loc_input.__dict__[\"widget\"].children[1].__dict__[\"_trait_values\"][\"value\"]\n",
    "#Fill dataframe with data from FLDAS files\n",
    "df_time_index = 0\n",
    "for month in all_months:\n",
    "\n",
    "    file_name = r\"data/FLDAS_NOAH01_C_GL_M.A\" + month[0:4]+ month[5:7] + \".001.nc.SUB.nc4\"\n",
    "    data = Dataset(file_name, 'r')\n",
    "    #print(file_name)\n",
    "    \n",
    "    # storing the lat and lon data into variables of netCDF file\n",
    "    lat = data.variables['Y'][:]\n",
    "    lon = data.variables['X'][:]\n",
    "    \n",
    "    #squared diff of lat and lon\n",
    "    sq_diff_lat = (lat - lat_user)**2\n",
    "    sq_diff_lon = (lon - lon_user)**2\n",
    "    \n",
    "    #getindex of minimum sq difference\n",
    "    min_index_lat =sq_diff_lat.argmin()\n",
    "    min_index_lon = sq_diff_lon.argmin()\n",
    "    \n",
    "    #accessing the soil moisture data and storing it into the final dataframe\n",
    "    air_temp = data.variables['Tair_f_tavg']\n",
    "    humidity = data.variables['Qair_f_tavg']\n",
    "    net_short_radiation = data.variables['SWdown_f_tavg']\n",
    "    net_long_radiation = data.variables['Lwnet_tavg']\n",
    "    wind_speed = data.variables['Wind_f_tavg']\n",
    "    evapotranspiration = data.variables['Evap_tavg']\n",
    "\n",
    "\n",
    "    #possibly creating the time range for each month and each iteration\n",
    "    #start = month\n",
    "    #d_range = pd.date\n",
    "   # df.iloc[df_time_index] = SM40[0,min_index_lat, min_index_lon]\n",
    "    df.air_temp[df_time_index] = air_temp[0,min_index_lat, min_index_lon]\n",
    "    df.humidity[df_time_index] = humidity[0,min_index_lat, min_index_lon]\n",
    "    df.net_short_radiation[df_time_index] = net_short_radiation[0,min_index_lat, min_index_lon]\n",
    "    df.net_long_radiation[df_time_index] = net_long_radiation[0,min_index_lat, min_index_lon]\n",
    "    df.wind_speed[df_time_index] = wind_speed[0,min_index_lat, min_index_lon]\n",
    "    df.evapotranspiration[df_time_index] = evapotranspiration[0,min_index_lat, min_index_lon]\n",
    "\n",
    "\n",
    "    df_time_index += 1\n",
    "\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Converting Units\n",
    "\n",
    "We are using the [Penman-Monteith model (PM model)](https://en.wikipedia.org/wiki/Penman%E2%80%93Monteith_equation#cite_note-1) to calculate the seasonal crop water requirement. In order to input the variables we need to convert the units from the FLDAS data to units utilized by the Penman-Monteith model. \n",
    "\n",
    "In the following table we change: \n",
    "- evapotranspiration from kilograms per second to millimeter per day\n",
    "- wind from 10 meter elevation to 2 meter elevation\n",
    "- temperature from Kelvin to Celsius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "tags": [
     "\"hide-input\""
    ]
   },
   "outputs": [],
   "source": [
    "hide_code()\n",
    "run_code()\n",
    "#converting units to correct measures for the PM equation\n",
    "# converts kg/m^2/s to mm/day\n",
    "def convert_to_mm_day(eot):\n",
    "    return eot * 86400\n",
    "df['evapotranspiration'] = df['evapotranspiration'].apply(convert_to_mm_day)\n",
    "\n",
    "# converts wind speed at 10m elevation to wind speed at a 2m elevation\n",
    "def convert_wind(speed):\n",
    "    return speed * 4.87 / math.log ( 67.8 * 10 - 5.42 ) \n",
    "df['wind_speed'] = df['wind_speed'].apply(convert_wind)\n",
    "\n",
    "\n",
    "#converts Kelvin to Celcius\n",
    "def convert_to_C(temp):\n",
    "    return temp -273.15\n",
    "df['air_temp'] = df['air_temp'].apply(convert_to_C)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Elevation data\n",
    "\n",
    "We then look up the elevation for our location from the downloaded elevation data for our desired location as an input for the Penman-Monteith model algorithm. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "tags": [
     "\"hide-input\""
    ]
   },
   "outputs": [],
   "source": [
    "hide_code()\n",
    "run_code()\n",
    "#gets elevation in meters using google elevation api\n",
    "#might need to square diff it\n",
    "\n",
    "elevation = elev_dict[(lat_user,lon_user)]\n",
    "print (\"Elevation:\", elevation, \"meters\")\n",
    "\n",
    "\n",
    "#Adding in dates, months and Vapor pressure\n",
    "dfvp = pd.DataFrame(0.0, columns = [], index = date_range)\n",
    "dfvp.index.name = 'Date'\n",
    "dfvp[\"dates\"] =  pd.date_range(start = month_start, end = month_end, freq = 'MS' ) \n",
    "dfvp['month'] = dfvp['dates'].dt.month \n",
    "\n",
    "vp = [5.7, 5.7, 6.7, 8.5, 13.2, 15.7, 18.4, 20.4, 17.4, 12.3, 8.1, 6.3]\n",
    "def months(x , vp):\n",
    "        return vp[x-1]\n",
    "\n",
    "dfvp['VP'] = dfvp.apply(lambda row: months(row.month , vp) , axis=1)\n",
    "df[\"VP\"] = dfvp[\"VP\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Water Requirement Calculator \n",
    "\n",
    "Next, we use the [Python Crop Simulation Environment](https://pcse.readthedocs.io/en/stable/) and specifically the Penman-Monteith algorithm to calculate the Water Requirement Satsification Index (WRSI) for each month in the dataframe adding the WR (water requirement on the far right of the dataframe). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "tags": [
     "\"hide-input\""
    ]
   },
   "outputs": [],
   "source": [
    "hide_code()\n",
    "run_code()\n",
    "#Calculating WR\n",
    "df[\"dates\"] = dfvp[\"dates\"]\n",
    "#pcse.util.penman_monteith(DAY, LAT, ELEV, TMIN, TMAX, AVRAD, VAP, WIND2)\n",
    "df['WR'] = df.apply(lambda row:  pcse.util.penman_monteith(row.dates, lat_user, elevation, row.air_temp , row.air_temp , row.net_short_radiation, row.VP, row.wind_speed), axis=1)\n",
    "del df[\"dates\"]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Calculating final WRSI (Water Requirement Satisfaction Index)\n",
    "\n",
    "We use evapotranspiration and WR to calculate the final Water Requirement Satisfaction Index for each month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "tags": [
     "\"hide-input\""
    ]
   },
   "outputs": [],
   "source": [
    "hide_code()\n",
    "run_code()\n",
    "#Calculate final WRSI\n",
    "df['WRSI'] = df.apply(lambda row:  100* (row.evapotranspiration/row.WR), axis=1)\n",
    "df\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Crop specific Water Requirements\n",
    "\n",
    "Finally, we calculate a general WRSI. However, we can find the crop specific WRSI data based on how much water a crop requires at diffent stages of its growth. We used the crop co-efficients from the online [United Nations Food and Agricultural Guidelines for Computing Crop Water Requirements](http://www.fao.org/3/X0490e/x0490e0b.htm#crop%20coefficients). \n",
    "\n",
    "### Please pick your crops and their life cycle(s) of interest.\n",
    "\n",
    "* Plant - Water requirements at planting\n",
    "* Grow - Water requirements during growth\n",
    "* Harvest - Water requirements at harvest time\n",
    "\n",
    "(Shift for group of selections; Ctrl-Shift for multiple individual selections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "\"hide-input\""
    ]
   },
   "outputs": [],
   "source": [
    "hide_code()\n",
    "run_code()\n",
    "crop_human = widgets.SelectMultiple(\n",
    "    options = [\"cowpeas : plant\", \"cowpeas : grow\", \"cowpeas : harvest\", \n",
    "               \"spring wheat : plant\", \"spring wheat : grow\", \"spring wheat : harvest\",\n",
    "              \"ground nut : plant\", \"ground nut : grow\", \"ground nut : harvest\", \n",
    "              \"maize : plant\", \"maize : grow\", \"maize : harvest\", \n",
    "              \"millet : plant\", \"millet : grow\", \"millet : harvest\",\n",
    "              \"sorghum : plant\", \"sorghum : grow\", \"sorghum : harvest\"],\n",
    "    description='Crops',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "crop_selected = []\n",
    "def update(crops):\n",
    "    crop_selected = list(crops)\n",
    "    return crop_selected\n",
    "\n",
    "crops_selection = interact(update, crops= crop_human)\n",
    "\n",
    "\n",
    "grazing = widgets.SelectMultiple(\n",
    "    options = [\"rotated grazing : grow\", \"rotated grazing : harvest\",\n",
    "               \"extensive grazing : grow\", \"extensive grazing : harvest\"], \n",
    "    description=\"Grazing\", \n",
    "    disabled = False)\n",
    "\n",
    "\n",
    "graze = []\n",
    "def g_update(grazing):\n",
    "    graze_selected = list(grazing)\n",
    "    return graze_selected\n",
    "    \n",
    "graze_selection = interact(g_update, grazing = grazing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "hide_code()\n",
    "run_code()\n",
    "\n",
    "crops = list(crops_selection.__dict__[\"widget\"].children[0].__dict__[\"_trait_values\"][\"value\"])\n",
    "grazes = list(graze_selection.__dict__[\"widget\"].children[0].__dict__[\"_trait_values\"][\"value\"])\n",
    "\n",
    "crop_dict = {\"cowpeas\":[0.4, 1.05,0.6],\n",
    "            \"maize\": [0.7,1.20, .35], \n",
    "             \"millet\":[.7,1.20, .35], \n",
    "             \"sorghum\":[.7, 1.20, .35], \n",
    "             \"spring wheat\": [0.4, 1.15,0.33], \n",
    "             \"ground nut\": [0.4, 1.15, 0.6], \n",
    "             \"rotated grazing\": [None, 1.05, 0.85],\n",
    "             \"extensive grazing\": [None,0.75,0.75]}\n",
    "\n",
    "#cowpeas,spring wheat, ground nut and grazing have variable requirements...figure out how to deal with that. \n",
    "\n",
    "reqs = {}\n",
    "\n",
    "def parse_crops(food):\n",
    "    '''\n",
    "    param: list of user inputs from crop and gazing selection \n",
    "    output: dictionary with crop and lifecycle times\n",
    "    '''\n",
    "   \n",
    "    \n",
    "    for f in food: \n",
    "        inputs = f.split(':')\n",
    "        crop = inputs[0][0:-1] # get rid of final space\n",
    "        cycle = inputs[1][1:] #get rid of lead space\n",
    "                    \n",
    "        if crop not in reqs.keys(): \n",
    "            reqs[crop] =[cycle]\n",
    "        else: \n",
    "            reqs[crop].append(cycle)\n",
    "    \n",
    "    return reqs\n",
    "\n",
    "reqs = parse_crops(crops)\n",
    "reqs = parse_crops(grazes)\n",
    "\n",
    "\n",
    "#Initializing empty data frame\n",
    "dfcrops = pd.DataFrame(0.0, columns = [], index = date_range)\n",
    "dfcrops.index.name = 'Date'\n",
    "\n",
    "def get_cycle(cycle):\n",
    "    cycle_idx = \"\"\n",
    "    if cycle == \"plant\":\n",
    "        cycle_idx = 0\n",
    "    elif cycle == \"grow\":\n",
    "        cycle_idx = 1\n",
    "    else: \n",
    "        cycle_idx = 2\n",
    "    return cycle_idx\n",
    "\n",
    "def make_crop_df(reqs):\n",
    "    \n",
    "    for crop,cycle in reqs.items(): \n",
    "        for c in cycle: \n",
    "            idx = get_cycle(c)\n",
    "            dfcrops[crop+\" \" + c] = df[\"WRSI\"]/crop_dict[crop][idx]\n",
    "\n",
    "make_crop_df(reqs)\n",
    "dfcrops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Data\n",
    "\n",
    "Now we can plot the final WRSI(Seasonal Water Requirement Satisfaction Index) models for each crop/crop stage. The WRSI model calculates the crop yield in relation to a water deficit. It follows the scale\n",
    "\n",
    "100+: Very Good\n",
    "\n",
    "95-100: Good\n",
    "\n",
    "80-94: Average\n",
    "\n",
    "60-79: Mediocre\n",
    "\n",
    "50-59: Poor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "\"hide-input\""
    ]
   },
   "outputs": [],
   "source": [
    "hide_code()\n",
    "run_code()\n",
    "\n",
    "columns = list(dfcrops.columns)\n",
    "\n",
    "plots = widgets.SelectMultiple(\n",
    "    options = columns, \n",
    "    description=\"Data to Plot\", \n",
    "    disabled = False)\n",
    "\n",
    "title = widgets.Text(\n",
    "    value='Crop Yields',\n",
    "    description='Title',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "font = widgets.IntText(\n",
    "    value=10,\n",
    "    description='Font Size',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "size = widgets.IntText(\n",
    "    value=600,\n",
    "    description='Plot Size',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "to_plot = []\n",
    "def plot_update(plots, title, font, size):\n",
    "    to_plot = list(plots)\n",
    "    font_label = str(font)+\"pt\"\n",
    "    axis_label = str(font*1.5) + \"pt\"\n",
    "    title_label = str(font*2)+\"pt\"\n",
    "    leg = []\n",
    "    ph = size\n",
    "    if len(to_plot) == 0:\n",
    "        pass\n",
    "    else: \n",
    "        above = 0\n",
    "        p = figure(plot_width=size, plot_height=ph, title=title, x_range = list(dfcrops.index.astype(str)))\n",
    "        p.xaxis.major_label_orientation = 45\n",
    "        p.title.text_font_size = title_label\n",
    "        p.xaxis.axis_label_text_font_size = font_label\n",
    "        p.xaxis.axis_label = \"Date\"\n",
    "        p.yaxis.axis_label = \"Water Satisfication\"\n",
    "        for plot, color in zip(to_plot, Spectral4): \n",
    "            l = p.line(list(dfcrops.index.astype(str)), dfcrops[plot], color = color, line_width = 2)\n",
    "            if max(dfcrops[plot]) > above:\n",
    "                above = max(dfcrops[plot])\n",
    "            leg.append((plot, [l]))\n",
    "        legend = Legend(items= leg, location=(0,ph/2))\n",
    "        green_box = BoxAnnotation(top=above+10, bottom=94, fill_color='green', fill_alpha=0.2)\n",
    "        yellow_box = BoxAnnotation(top=94, bottom=80, fill_color='yellow', fill_alpha=0.2)\n",
    "        orange_box = BoxAnnotation(top=80, bottom=50, fill_color='orange', fill_alpha=0.2)\n",
    "        red_box = BoxAnnotation(top=50, bottom=0, fill_color='red', fill_alpha=0.2)\n",
    "        boxes = [green_box, yellow_box, orange_box, red_box]\n",
    "        p.add_layout(legend, \"right\")\n",
    "       \n",
    "        for box in boxes: \n",
    "            p.add_layout(box)\n",
    "                \n",
    "        toggle1 = Toggle(label=\"Good Water\", button_type=\"success\", active=True)\n",
    "        toggle1.js_link('active', green_box, 'visible')\n",
    "        \n",
    "        toggle2 = Toggle(label= \"Average Water\", button_type=\"success\", active=True)\n",
    "        toggle2.js_link('active', yellow_box, 'visible')\n",
    "        \n",
    "        toggle3 = Toggle(label=\"Mediocre Water\", button_type=\"success\", active=True)\n",
    "        toggle3.js_link('active', orange_box, 'visible')\n",
    "        \n",
    "        toggle4 = Toggle(label=\"Poor Water\", button_type=\"success\", active=True)\n",
    "        toggle4.js_link('active', red_box, 'visible')\n",
    "        #inputs = column(plots, title, font, size)\n",
    "        show(layout([p], [toggle1, toggle2], [toggle3, toggle4]))\n",
    "            \n",
    "\n",
    "plot_selection = interact(plot_update, plots = plots, title = title, font = font, size = size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": true,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
